{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goal: Locate suspects faster through rapid car identification. \n",
    "# Biz Goal: Highly engaging POC, highly marketable, attention grabbing\n",
    "\n",
    "# How: \n",
    "#- Video to image (later, tracking across frames)\n",
    "#- Object Detection to find license plates\n",
    "#- OCR to pull LP#\n",
    "#- DF search & match to find relevant information.\n",
    "\n",
    "#Notes: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Replace 'path_to_video_file' with the actual path to your video file\n",
    "video_file_path = '/Users/whit_blodgett/Desktop/Code/landing-apps-poc/IMG_2075.mov'\n",
    "\n",
    "# 1. iPhone Video to image\n",
    "def extract_frames(video_file_path):\n",
    "    vidcap = cv2.VideoCapture(video_file_path)\n",
    "    success, image = vidcap.read()\n",
    "    count = 0\n",
    "    frames = []\n",
    "    while success:\n",
    "        # save every 30th frame as jpg file (you can modify this based on your requirement)\n",
    "        if count % 100 == 0:\n",
    "            frames.append(image)\n",
    "        success, image = vidcap.read()\n",
    "        count += 1\n",
    "    return frames\n",
    "\n",
    "frames = extract_frames(video_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def display_frames(frames):\n",
    "#     for frame in frames:\n",
    "#         cv2.imshow('Frame', frame)\n",
    "#         if cv2.waitKey(25) & 0xFF == ord('q'):  # Press 'q' to exit the display loop\n",
    "#             break\n",
    "\n",
    "#     # Release the video display window and close it\n",
    "#     cv2.destroyAllWindows()\n",
    "\n",
    "# # display_frames(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_license_plates(frames):\n",
    "    bounding_boxes = []\n",
    "    url = 'https://predict.app.landing.ai/inference/v1/predict?endpoint_id=972bcd20-31fc-4537-96f4-8b92e3a91408'\n",
    "    headers = {'apikey': 'land_sk_OdafnFLV340HT1eCdvm3Z4X3Xev8VP58iAhfqh6hAdnORL9ySq'\n",
    "    }\n",
    "    \n",
    "    for frame in frames:\n",
    "        img = cv2.imencode(\".jpg\", frame)[1]\n",
    "        cv2.imshow('frame', frame)\n",
    "        cv2.waitKey(1)\n",
    "\n",
    "        files = [(\"file\", (\"image.jpg\", img, \"image/jpg\"))]\n",
    "        response = requests.post(url, headers=headers, files=files)\n",
    "        if response.status_code != 200:\n",
    "                print(\"error!\")\n",
    "                time.sleep(5)\n",
    "                continue\n",
    "\n",
    "        prediction = response.json()\n",
    "        # store predictions in a list\n",
    "        bounding_boxes.append(prediction)\n",
    "    return bounding_boxes\n",
    "\n",
    "bounding_boxes = detect_license_plates(frames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'backbonetype': 'ObjectDetectionPrediction', 'backbonepredictions': {}, 'predictions': {'score': 0.0, 'labelIndex': 0, 'labelName': 'OK'}, 'type': 'ClassificationPrediction', 'latency': {'preprocess_s': 0.006475925445556641, 'infer_s': 0.2851595878601074, 'postprocess_s': 0.00010633468627929688, 'serialize_s': 0.0023508071899414062, 'input_conversion_s': 0.012464046478271484, 'model_loading_s': 5.6210315227508545}, 'model_id': '05cf1304-3de9-49db-996a-9bfa6ad36885'}, {'backbonetype': 'ObjectDetectionPrediction', 'backbonepredictions': {}, 'predictions': {'score': 0.0, 'labelIndex': 0, 'labelName': 'OK'}, 'type': 'ClassificationPrediction', 'latency': {'preprocess_s': 0.007235527038574219, 'infer_s': 0.2747361660003662, 'postprocess_s': 0.00010561943054199219, 'serialize_s': 0.0023033618927001953, 'input_conversion_s': 0.007213592529296875, 'model_loading_s': 5.353914260864258}, 'model_id': '05cf1304-3de9-49db-996a-9bfa6ad36885'}, {'backbonetype': 'ObjectDetectionPrediction', 'backbonepredictions': {}, 'predictions': {'score': 0.0, 'labelIndex': 0, 'labelName': 'OK'}, 'type': 'ClassificationPrediction', 'latency': {'preprocess_s': 0.00912165641784668, 'infer_s': 0.15705394744873047, 'postprocess_s': 8.654594421386719e-05, 'serialize_s': 0.0027534961700439453, 'input_conversion_s': 0.00803995132446289, 'model_loading_s': 8.082389831542969e-05}, 'model_id': '05cf1304-3de9-49db-996a-9bfa6ad36885'}, {'backbonetype': 'ObjectDetectionPrediction', 'backbonepredictions': {}, 'predictions': {'score': 0.0, 'labelIndex': 0, 'labelName': 'OK'}, 'type': 'ClassificationPrediction', 'latency': {'preprocess_s': 0.00630497932434082, 'infer_s': 0.16657090187072754, 'postprocess_s': 9.489059448242188e-05, 'serialize_s': 0.0024106502532958984, 'input_conversion_s': 0.01004338264465332, 'model_loading_s': 8.320808410644531e-05}, 'model_id': '05cf1304-3de9-49db-996a-9bfa6ad36885'}, {'backbonetype': 'ObjectDetectionPrediction', 'backbonepredictions': {'3046b212-f1a1-4329-9c7b-551b653199f8': {'score': 0.9221176505088806, 'defect_id': 84690, 'coordinates': {'xmin': 104, 'ymin': 465, 'xmax': 217, 'ymax': 520}, 'labelIndex': 2, 'labelName': 'number_plate'}}, 'predictions': {'score': 0.9221176505088806, 'labelIndex': 1, 'labelName': 'NG'}, 'type': 'ClassificationPrediction', 'latency': {'preprocess_s': 0.00636601448059082, 'infer_s': 0.15578961372375488, 'postprocess_s': 0.0003383159637451172, 'serialize_s': 0.002970457077026367, 'input_conversion_s': 0.008147478103637695, 'model_loading_s': 7.677078247070312e-05}, 'model_id': '05cf1304-3de9-49db-996a-9bfa6ad36885'}, {'backbonetype': 'ObjectDetectionPrediction', 'backbonepredictions': {}, 'predictions': {'score': 0.0, 'labelIndex': 0, 'labelName': 'OK'}, 'type': 'ClassificationPrediction', 'latency': {'preprocess_s': 0.006217241287231445, 'infer_s': 0.1629164218902588, 'postprocess_s': 9.894371032714844e-05, 'serialize_s': 0.002153635025024414, 'input_conversion_s': 0.008626937866210938, 'model_loading_s': 7.987022399902344e-05}, 'model_id': '05cf1304-3de9-49db-996a-9bfa6ad36885'}, {'backbonetype': 'ObjectDetectionPrediction', 'backbonepredictions': {}, 'predictions': {'score': 0.0, 'labelIndex': 0, 'labelName': 'OK'}, 'type': 'ClassificationPrediction', 'latency': {'preprocess_s': 0.0070874691009521484, 'infer_s': 0.16315579414367676, 'postprocess_s': 0.00011205673217773438, 'serialize_s': 0.002270936965942383, 'input_conversion_s': 0.009043216705322266, 'model_loading_s': 7.43865966796875e-05}, 'model_id': '05cf1304-3de9-49db-996a-9bfa6ad36885'}, {'backbonetype': 'ObjectDetectionPrediction', 'backbonepredictions': {}, 'predictions': {'score': 0.0, 'labelIndex': 0, 'labelName': 'OK'}, 'type': 'ClassificationPrediction', 'latency': {'preprocess_s': 0.006242513656616211, 'infer_s': 0.16285490989685059, 'postprocess_s': 9.775161743164062e-05, 'serialize_s': 0.0022275447845458984, 'input_conversion_s': 0.008295536041259766, 'model_loading_s': 7.224082946777344e-05}, 'model_id': '05cf1304-3de9-49db-996a-9bfa6ad36885'}, {'backbonetype': 'ObjectDetectionPrediction', 'backbonepredictions': {}, 'predictions': {'score': 0.0, 'labelIndex': 0, 'labelName': 'OK'}, 'type': 'ClassificationPrediction', 'latency': {'preprocess_s': 0.006533384323120117, 'infer_s': 0.15984249114990234, 'postprocess_s': 0.0001087188720703125, 'serialize_s': 0.0027456283569335938, 'input_conversion_s': 0.008402824401855469, 'model_loading_s': 8.96453857421875e-05}, 'model_id': '05cf1304-3de9-49db-996a-9bfa6ad36885'}, {'backbonetype': 'ObjectDetectionPrediction', 'backbonepredictions': {}, 'predictions': {'score': 0.0, 'labelIndex': 0, 'labelName': 'OK'}, 'type': 'ClassificationPrediction', 'latency': {'preprocess_s': 0.006484031677246094, 'infer_s': 0.16566801071166992, 'postprocess_s': 0.00011324882507324219, 'serialize_s': 0.0020520687103271484, 'input_conversion_s': 0.006954193115234375, 'model_loading_s': 7.510185241699219e-05}, 'model_id': '05cf1304-3de9-49db-996a-9bfa6ad36885'}, {'backbonetype': 'ObjectDetectionPrediction', 'backbonepredictions': {}, 'predictions': {'score': 0.0, 'labelIndex': 0, 'labelName': 'OK'}, 'type': 'ClassificationPrediction', 'latency': {'preprocess_s': 0.0069429874420166016, 'infer_s': 0.1634206771850586, 'postprocess_s': 0.00010085105895996094, 'serialize_s': 0.0025167465209960938, 'input_conversion_s': 0.007130146026611328, 'model_loading_s': 5.507469177246094e-05}, 'model_id': '05cf1304-3de9-49db-996a-9bfa6ad36885'}, {'backbonetype': 'ObjectDetectionPrediction', 'backbonepredictions': {}, 'predictions': {'score': 0.0, 'labelIndex': 0, 'labelName': 'OK'}, 'type': 'ClassificationPrediction', 'latency': {'preprocess_s': 0.006360769271850586, 'infer_s': 0.15705037117004395, 'postprocess_s': 0.00011587142944335938, 'serialize_s': 0.002122163772583008, 'input_conversion_s': 0.006770133972167969, 'model_loading_s': 7.319450378417969e-05}, 'model_id': '05cf1304-3de9-49db-996a-9bfa6ad36885'}, {'backbonetype': 'ObjectDetectionPrediction', 'backbonepredictions': {}, 'predictions': {'score': 0.0, 'labelIndex': 0, 'labelName': 'OK'}, 'type': 'ClassificationPrediction', 'latency': {'preprocess_s': 0.006795167922973633, 'infer_s': 0.15611600875854492, 'postprocess_s': 0.00011038780212402344, 'serialize_s': 0.0021123886108398438, 'input_conversion_s': 0.005716562271118164, 'model_loading_s': 7.700920104980469e-05}, 'model_id': '05cf1304-3de9-49db-996a-9bfa6ad36885'}, {'backbonetype': 'ObjectDetectionPrediction', 'backbonepredictions': {}, 'predictions': {'score': 0.0, 'labelIndex': 0, 'labelName': 'OK'}, 'type': 'ClassificationPrediction', 'latency': {'preprocess_s': 0.006278276443481445, 'infer_s': 0.17599797248840332, 'postprocess_s': 0.00010251998901367188, 'serialize_s': 0.0020711421966552734, 'input_conversion_s': 0.005703926086425781, 'model_loading_s': 7.367134094238281e-05}, 'model_id': '05cf1304-3de9-49db-996a-9bfa6ad36885'}]\n"
     ]
    }
   ],
   "source": [
    "print(bounding_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
